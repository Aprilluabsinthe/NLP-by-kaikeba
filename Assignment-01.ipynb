{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 今天是2019年9月28日，今天世界上又多了一名AI工程师 :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`各位同学大家好，欢迎各位开始学习我们的人工智能课程。这门课程假设大家不具备机器学习和人工智能的知识，但是希望大家具备初级的Python编程能力。根据往期同学的实际反馈，我们课程的完结之后 能力能够超过80%的计算机人工智能/深度学习方向的硕士生的能力。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作业的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 复现课堂代码\n",
    "\n",
    "在本部分，你需要参照我们给大家的GitHub地址里边的课堂代码，结合课堂内容，复现内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 请回答以下问题\n",
    "\n",
    "回答以下问题，并将问题发送至 minchuian.gao@gmail.com 中：\n",
    "```\n",
    "    2.1. what do you want to acquire in this course？\n",
    "    2.2. what problems do you want to solve？\n",
    "    2.3. what’s the advantages you have to finish you goal?\n",
    "    2.4. what’s the disadvantages you need to overcome to finish you goal?\n",
    "    2.5. How will you plan to study in this course period?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 如何提交\n",
    "代码 + 此 jupyter 相关，提交至自己的 github 中(**所以请务必把GitHub按照班主任要求录入在Trello中**)；\n",
    "第2问，请提交至minchuian.gao@gmail.com邮箱。\n",
    "#### 4. 作业截止时间\n",
    "此次作业截止时间为 2019.10.8日"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: \n",
    "1/Information Retrieval;\n",
    "2/Similar Graphics Search Engine;\n",
    "3/Face recognition, fakeface apps changing faces "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: \n",
    "we should use GitHub as a repository as well as an open window to others who are interested in our project.\n",
    "As Github could be easily set permissions like 'private' and 'public', we could safely restore personal project and code in it. Also, if willing to share and be exposed to others, Github can also be used as an open-source collaboration community. With GitHub, I can let others participate in my open-source projects and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "it gives a probability that a string is a member of a language is more useful or more common used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in a string s, the probability p(s) depends on the elements within. The N-gram models estimate probabiliy of each word given the N prior words. A N-gram model uses only N-1 words of prior context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ w_1^n = w_1 \\cdot w_2 \\ldots w_n \\quad$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ p(w_1^n) = p(w_1)p(w_2 | w_1)p(w_2 | w_1^2) \\cdots p(w_n | w_1^{n-1}) = = \\prod_{k=1}^n {P({w_k | w_1^{k-1}})}  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ P(w_1^n) = \\prod_{k=1}^n{P(w_k | w_{k-1})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ P(w_1^n) = \\prod_{k=1}^n{P(w_k | w_{k-N+1}^{k-1})} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: we should use it in AI chatting apps where sentence generating is need. Probability Model helps the computer decide which sentence is more possibly accepted by a human speaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: The model is direct to be understood and relatively easy to be completed, turning a language problem to a statistical problem using an easy math model. The model is simple in that it does not contain several layers yet still effective to some extent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are many difficulties: 1\\  If we need to ensure model accuracy, a lot of data will be required. The training process needs huge amount of human sentence data to calculate the probability. 2\\ the effectiveness of the model highly depends on what was given to the model. A huge sentence data limited in a specific field will lead to wrongly evaluated. 3\\ The probability is not very accurate. Especially when the N in the n-gram is very large, the data can be relatively sparse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  Language Model is formal grammars, for example, regular and context-free, give a strict 'binary' model of the legal sentences in a language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:1\\speech recognition : evaluate which sentence is a more likely sentence. 2\\OCR & handwriting recognition : more probably sentences are more likely correct readings.3\\machine translation : more likely sentences are peobably better translations.  4\\context sensitive spelling correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: do not depend on prior words but only calculate the probability of one single word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: advantage : speed of calculation is faster. disadvantage : low accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: the simplest improvement of the 1-gram language model. The model depends on the immediate word prior to it, calculating the probability when the combining word occurs when detecting one specific word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何生成句子是一个很经典的问题，从1940s开始，图灵提出机器智能的时候，就使用的是人类能不能流畅和计算机进行对话。和计算机对话的一个前提是，计算机能够生成语言。\n",
    "\n",
    "计算机如何能生成语言是一个经典但是又很复杂的问题。 我们课程上为大家介绍的是一种基于规则（Rule Based）的生成方法。该方法虽然提出的时间早，但是现在依然在很多地方能够大显身手。值得说明的是，现在很多很实用的算法，都是很久之前提出的，例如，二分查找提出与1940s, Dijstra算法提出于1960s 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在著名的电视剧，电影《西部世界》中，这些机器人们语言生成的方法就是使用的SyntaxTree生成语言的方法。\n",
    "\n",
    "> \n",
    ">\n",
    "\n",
    "![WstWorld](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1569578233461&di=4adfa7597fb380e7cc0e67190bbd7605&imgtype=0&src=http%3A%2F%2Fs1.sinaimg.cn%2Flarge%2F006eYYfyzy76cmpG3Yb1f)\n",
    "\n",
    "> \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请定义你自己的语法: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_rules ='''\n",
    "sentence = oneself seek activity \n",
    "oneself = 我 | 俺 | 我们 \n",
    "seek = 看看 | 找找 | 想找点\n",
    "activity = 乐子 | 玩的\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_rules = '''\n",
    "sentence = greeting one_NO request about_service tail \n",
    "one_NO = 我是 number 号 ,\n",
    "number = singlenumber | number singlenumber \n",
    "singlenumber = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "greeting = title say_hello , | say_hello ,\n",
    "title = benamed ,\n",
    "benamed = 先生 | 女士 | 小朋友\n",
    "say_hello = 你好 | 您好 \n",
    "request = 请问你要 | 您需要\n",
    "about_service = forfun service_detail\n",
    "forfun = 耍一耍 | 玩一玩\n",
    "service_detail = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "tail = 吗?\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，使用自己之前定义的generate函数，使用此函数生成句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt_split = '='\n",
    "expr_split = '|'\n",
    "trial_rules = dict()\n",
    "\n",
    "for line in host_rules.split('\\n'):\n",
    "    if not line : continue\n",
    "    stmt , expr = line.split(stmt_split)\n",
    "    trial_rules[stmt.strip()] = expr.split(expr_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 你好 ', ' 您好 ']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_rules['say_hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_by_gram(rules_dict , target): #rules_dict 是 字典\n",
    "    if target in rules_dict:\n",
    "        candidates = rules_dict[target]\n",
    "        candidate = random.choice(candidates)\n",
    "        return ''.join(generate_by_gram(rules_dict,target = c.strip()) for c in candidate.split())\n",
    "    else:\n",
    "        return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'女士,你好,我是19号,请问你要耍一耍打猎吗?'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_by_gram(trial_rules ,target = 'sentence' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(origin_rules , target , stmt_split = '=' , expr_split = '|'):\n",
    "    rules = dict()\n",
    "    for line in origin_rules.split('\\n'):\n",
    "        if not line : continue\n",
    "        stmt , expr = line.split(stmt_split)\n",
    "        rules[stmt.strip()] = expr.split(expr_split)\n",
    "    \n",
    "    return generate_by_gram(rules ,target = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好,我是12号,请问你要玩一玩打猎吗?\n"
     ]
    }
   ],
   "source": [
    "print(generate(host_rules , target = 'sentence'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(original_rules , target , repeat):\n",
    "    for i in range(repeat):\n",
    "        sen = generate(origin_rules = original_rules , target = target)\n",
    "        print(i+1, sen)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 小朋友,您好,我是8号,您需要玩一玩打牌吗?\n",
      "2 你好,我是7122号,请问你要玩一玩喝酒吗?\n",
      "3 小朋友,你好,我是4142497号,您需要耍一耍打猎吗?\n",
      "4 小朋友,您好,我是92号,请问你要耍一耍打牌吗?\n",
      "5 您好,我是7号,您需要耍一耍打牌吗?\n",
      "6 你好,我是696号,您需要耍一耍喝酒吗?\n",
      "7 你好,我是162号,请问你要玩一玩赌博吗?\n",
      "8 小朋友,您好,我是7号,请问你要耍一耍赌博吗?\n",
      "9 你好,我是22号,您需要玩一玩打牌吗?\n",
      "10 小朋友,你好,我是41号,您需要耍一耍打猎吗?\n"
     ]
    }
   ],
   "source": [
    "generate_n(host_rules , target = 'sentence' , repeat = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的`prob_2`函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "    + 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的**2-gram**语言模型\n",
    "    + 进行文本清洗，获得所有的纯文本\n",
    "    + 将这些文本进行切词\n",
    "    + 送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分词封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 引入数据源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_douban = 'C:/Users/四月鹿April/Documents/NLP-learning/lesson-1/movie_comments_chinese1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_insurance = 'C:/Users/四月鹿April/Documents/NLP-learning/lesson-1/train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_insurance = open(corpus_insurance, encoding = 'utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_douban = open(corpus_douban , encoding = 'utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id,link,name,comment,star\\n1,https://movie.douban.com/subject/26363254/,战狼2,吴京意淫到了脑残的地步，看了恶心想吐,1\\n2,ht'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_douban[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 ++$++ disability-insurance ++$++ 法律要求残疾保险吗？ ++$++ Is  Disability  Insurance  Required  By  Law?\\n1 '"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_insurance[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 清洗数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_data( origin_files , frag_split = ','):\n",
    "    new_file = ''\n",
    "    for line in origin_files.split('\\n'):\n",
    "        for i in line.split(frag_split):\n",
    "            new_file += re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]\",string(i))\n",
    "    \n",
    "    return new_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_data( origin_files , frag_split = ','):\n",
    "    punctuation = '《（）》…!-,.;:?\"，。：/\\s\\n'\n",
    "    new_file = ''\n",
    "    for ele in origin_files.split(frag_split): \n",
    "        text = re.sub(r'[{}]'.format(punctuation),'',ele)\n",
    "        new_file += text.strip()\n",
    "    return new_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_insurance_wash = wash_data( FILE_insurance , frag_split = ' ++$++ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0disability-insurance法律要求残疾保险吗？IsDisabilityInsuranceRequiredByLaw1life-insurance债权人可以在死后人寿保险吗？CanCreditorsTakeLifeInsuranceAfterDeath2renters-insurance旅行者保险有租赁保险吗？DoesTravelersInsuranceHaveRentersInsurance3auto-insurance我可以开一辆没有保险的新车吗？CanIDriveANewCarHomeWithoutInsurance4life-insurance人寿保险的现金转出价值是否应纳税？IsTheCashSurrenderValueOfLifeInsuranceTaxable5annuities如何报告年金收入？HowIsAnnuityIncomeReported6home-insuranceAAA家庭保险涵盖什么？WhatDoesAAAHomeInsuranceCover7retirement-plans什么是简单的退休计划？WhatIsASimpleRetirementPlan8disability-insurance社会保险残疾保险是什么？WhatDoesSocialSecurityDisabilityInsuranceCover9auto-insurance汽车保险是否预付？IsCarInsurancePrepaid10medicare-insurance医疗保险B部分盖什么？WhatDoesMedicarePartBCover11life-insurance退伍军人能否获得人寿保险？CanVeteransGetLifeInsurance12home-insurance我的房主保险是否包括失去的结婚戒指？DoesMyHomeownersInsuranceCoverLostWeddingRing13auto-insurance分配风险汽车保险如何工作？HowDoesAssignedRiskAutoInsuranceWork14auto-insurance我的男朋友可以加我的汽车保险吗？CanMyBoyfriendAddMeToHisCarInsurance15auto-insurance我是否需要提交私人财产车祸索赔的警察报告？DoINeedAPo'"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_insurance_wash[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_douban_wash = wash_data(FILE_douban[:1500000] , frag_split = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'idlinknamecommentstar1httpsmoviedoubancomsubject26363254战狼2吴京意淫到了脑残的地步看了恶心想吐12httpsmoviedoubancomsubject26363254战狼2首映礼看的太恐怖了这个电影不讲道理的完全就是吴京在实现他这个小粉红的英雄梦各种装备轮番上场视物理逻辑于不顾不得不说有钱真好随意胡闹23httpsmoviedoubancomsubject26363254战狼2吴京的炒作水平不输冯小刚但小刚至少不会用主旋律来炒作吴京让人看了不舒服为了主旋律而主旋律为了煽情而煽情让人觉得他是个大做作、大谎言家729更新片子整体不如湄公河行动1整体不够流畅编剧有毒台词尴尬；2刻意做作的主旋律煽情显得如此不合时宜而又多余24httpsmoviedoubancomsubject26363254战狼2凭良心说好看到不像战狼1的续集完虐湄公河行动45httpsmoviedoubancomsubject26363254战狼2中二得很16httpsmoviedoubancomsubject26363254战狼2“犯我中华者虽远必诛”吴京比这句话还要意淫一百倍17httpsmoviedoubancomsubject26363254战狼2脑子是个好东西希望编剧们都能有28httpsmoviedoubancomsubject26363254战狼2三星半实打实的7分第一集在爱国主旋律内部做着各种置换与较劲但第二集才真正显露吴京的野心他终于抛弃李忠志了新增外来班底让硬件实力有机会和国际接轨开篇水下长镜头和诸如铁丝网拦截RPG弹头的细节设计都让国产动作片重新封顶在理念上它甚至做到绣春刀2最想做到的那部分49httpsmoviedoubancomsubject26363254战狼2开篇长镜头惊险大气引人入胜结合了水平不俗的快剪下实打实的真刀真枪让人不禁热血沸腾特别弹簧床架挡炸弹空手接碎玻璃弹匣割喉等帅得飞起！就算前半段铺垫节奏散漫主角光环开太大等也不怕作为一个中国人两个小时弥漫着中国强大得不可侵犯的氛围还是让那颗民族自豪心砰砰砰跳个不停410httpsmoviedoubancomsubject26363254战狼215100吴京的冷峰在这部里即像成龙又像杰森斯坦森但体制外的同类型电影主角总是代表个人无能的政府需要求助于这些英雄才能解决难题'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_douban_wash[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### jieba.cut 数据源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS_insurance = cut(FILE_insurance_wash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS_douban = cut(FILE_douban_wash[:1500000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义分词函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(string):\n",
    "    return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义单个词和组合词的Counter函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1_word_count(word):\n",
    "    if word in word_count: return word_count[word]\n",
    "    else:\n",
    "        return word_count.most_common()[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2_word_count(word):\n",
    "    if word in _2_words_count: return _2_words_count[word]\n",
    "    else:\n",
    "        return _2_words_count.most_common()[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_count(word , wordtype):\n",
    "    if word in wordtype: return wordtype[word]\n",
    "    else:\n",
    "        return wordtype.most_common()[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-gram 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proba_2_gram_model( TOKENS_source , sentence):\n",
    "\n",
    "    word_count_source = Counter(TOKENS_source)\n",
    "    \n",
    "    _2_words_source = [TOKENS_source[i]+TOKENS_source[i+1] for i in range(len(TOKENS_source)-1)]\n",
    "    _2_words_count_source = Counter(_2_words_source)\n",
    "    \n",
    "    tokens = cut(sentence)\n",
    "    P = 1\n",
    "    for i in range(len(tokens)-1):\n",
    "        word = tokens[i]\n",
    "        next_word = tokens[i+1]\n",
    "        pro = get_words_count(word + next_word , _2_words_count_source) / get_words_count(next_word ,word_count_source)\n",
    "        P *= pro\n",
    "    return P\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.697507133763e-06"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_2_gram_model( TOKENS_insurance , sentence = '什么是简单的退休计划')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.62000962000962e-05"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_2_gram_model( TOKENS_douban , sentence = '战狼战争场面非常宏伟')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008279973504084786"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_2_gram_model( TOKENS_insurance , sentence = '保险如何兑现')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2949432352004973e-06"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_2_gram_model( TOKENS_insurance , sentence = '我可以获得多大的人寿保险')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.201130820723901e-06"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_2_gram_model( TOKENS_douban , sentence = '电影故事很不错')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.030389194753e-10"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_2_gram_model( TOKENS_insurance , sentence = '战狼体现了对自己情绪的接纳')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([1, 3, 5, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数接受一个参数key，这个参数接受一个函数作为输入，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第0个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序, 但是是递减的顺序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### 判断最合理的句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(sets,source): # 一系列句子\n",
    "    sent = dict()\n",
    "    for i in sets:\n",
    "        sent[i]= proba_2_gram_model( source , i)\n",
    "    print(sent)\n",
    "    after = sorted(sent.items() , key=lambda x: x[1], reverse=True)\n",
    "    print('\\n最合理的句子是:\\n',after[1][0])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'这部电影真好看': 8.149059973032179e-06, '剧情有点混乱': 0.0006520422895999255}\n",
      "\n",
      "最合理的句子是:\n",
      " 这部电影真好看\n"
     ]
    }
   ],
   "source": [
    "generate_best(['这部电影真好看','剧情有点混乱'],TOKENS_douban)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = ['后半段明显是崩了','喜剧一定要深刻不落俗套','爱情戏草草收尾','前面的铺垫过长','有逻辑错误','电影非常热血','剧情真的非常精彩','电影的动机有点崩']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'后半段明显是崩了': 4.027063827685895e-10, '喜剧一定要深刻不落俗套': 3.4438463631260484e-06, '爱情戏草草收尾': 0.000676132521974307, '前面的铺垫过长': 1.613287031995515e-05, '有逻辑错误': 0.0018674136321195143, '电影非常热血': 0.00016233766233766236, '剧情真的非常精彩': 4.805555221836443e-06, '电影的动机有点崩': 1.0140742214855203e-06}\n",
      "\n",
      "最合理的句子是:\n",
      " 爱情戏草草收尾\n"
     ]
    }
   ],
   "source": [
    "generate_best(sets,TOKENS_douban)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = ['后半段明显是崩了','喜剧一定要深刻不落俗套','爱情戏草草收尾','前面的铺垫过长','有逻辑错误','电影非常热血','剧情真的非常精彩','电影的动机有点崩','学着点就好了','热血至死都是少年','我真的喜欢这种简单的纯爱电影','三颗星不能更多了','诚意十足但是不够']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 输入的格式限制严格，不够智能。应该加入更多输入格式的判断。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以下内容为可选部分，对于绝大多数同学，能完成以上的项目已经很优秀了，下边的内容如果你还有精力可以试试，但不是必须的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) 完成基于Pattern Match的语句问答\n",
    "> 我们的GitHub仓库中，有一个assignment-01-optional-pattern-match，这个难度较大，感兴趣的同学可以挑战一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. (Optional) 完成阿兰图灵机器智能原始论文的阅读\n",
    "1. 请阅读阿兰图灵关于机器智能的原始论文：https://github.com/Computing-Intelligence/References/blob/master/AI%20%26%20Machine%20Learning/Computer%20Machinery%20and%20Intelligence.pdf \n",
    "2. 并按照GitHub仓库中的论文阅读模板，填写完毕后发送给我: mqgao@kaikeba.com 谢谢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，我们已经完成了自己的第一个AI模型，大家对人工智能可能已经有了一些感觉，人工智能的核心就是，我们如何设计一个模型、程序，在外部的输入变化的时候，我们的程序不变，依然能够解决问题。人工智能是一个很大的领域，目前大家所熟知的深度学习只是其中一小部分，之后也肯定会有更多的方法提出来，但是大家知道人工智能的目标，就知道了之后进步的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，希望大家对AI不要有恐惧感，这个并不难，大家加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561828422005&di=48d19c16afb6acc9180183a6116088ac&imgtype=0&src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201807%2F28%2F20180728150843_BECNF.thumb.224_0.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
